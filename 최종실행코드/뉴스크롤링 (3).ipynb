{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wMnfi22FRe7T",
        "outputId": "b9663e90-4e6d-42d7-e19e-dc8ebdf06127"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.41.2)\n",
            "Collecting kobert-transformers\n",
            "  Downloading kobert_transformers-0.5.1-py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.15.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: torch>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from kobert-transformers) (2.3.0+cu121)\n",
            "Requirement already satisfied: sentencepiece>=0.1.91 in /usr/local/lib/python3.10/dist-packages (from kobert-transformers) (0.1.99)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->kobert-transformers) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->kobert-transformers) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->kobert-transformers) (3.1.4)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.1.0->kobert-transformers)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.1.0->kobert-transformers)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.1.0->kobert-transformers)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.1.0->kobert-transformers)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.1.0->kobert-transformers)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.1.0->kobert-transformers)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.1.0->kobert-transformers)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.1.0->kobert-transformers)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.1.0->kobert-transformers)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.1.0->kobert-transformers)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.1.0->kobert-transformers)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->kobert-transformers) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.1.0->kobert-transformers)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m35.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.6.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.1.0->kobert-transformers) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.1.0->kobert-transformers) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, kobert-transformers\n",
            "Successfully installed kobert-transformers-0.5.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105\n"
          ]
        }
      ],
      "source": [
        "pip install transformers kobert-transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 출처 : https://ai-creator.tistory.com/36\n",
        "# 출처 : https://novice-engineers.tistory.com/9\n",
        "# 출처 : https://github.com/uoneway/KoBertSum\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import json\n",
        "import torch\n",
        "from transformers import BertTokenizer, BertModel\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# 뉴스 기사 URL 입력\n",
        "url = input(\"뉴스 url을 입력해주세요: \")\n",
        "\n",
        "# 웹 페이지 요청\n",
        "response = requests.get(url)\n",
        "if response.status_code == 200:\n",
        "    # HTML 파싱\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "    # 기사 제목 크롤링\n",
        "    title_tag = soup.find('h2', {'class': 'media_end_head_headline'})\n",
        "    if title_tag:\n",
        "        title = title_tag.get_text()\n",
        "    else:\n",
        "        title = \"Title not found\"\n",
        "\n",
        "    # 기사 본문 크롤링\n",
        "    content_tag = soup.find('div', {'id': 'newsct_article'})\n",
        "    if content_tag:\n",
        "        content = content_tag.get_text(strip=True)\n",
        "    else:\n",
        "        content = \"Content not found\"\n",
        "\n",
        "    # KoBERT 모델과 토크나이저 로드\n",
        "    model = BertModel.from_pretrained('monologg/kobert')\n",
        "    tokenizer = BertTokenizer.from_pretrained('monologg/kobert')\n",
        "\n",
        "    # 텍스트 요약 함수\n",
        "    def summarize_text(text, max_length=5):\n",
        "        # 문장을 분리\n",
        "        sentences = text.split('. ')\n",
        "        # 문장을 토큰화하고 패딩 및 트렁케이션 적용\n",
        "        inputs = tokenizer(sentences, return_tensors='pt', padding=True, truncation=True)\n",
        "        with torch.no_grad():\n",
        "            # 모델을 통해 문장 임베딩 생성\n",
        "            outputs = model(**inputs)\n",
        "        sentence_embeddings = outputs.last_hidden_state.mean(dim=1)\n",
        "\n",
        "        # 문서 임베딩\n",
        "        doc_embedding = sentence_embeddings.mean(dim=0).unsqueeze(0)\n",
        "        # 유사도를 계산하여 상위 문장 선택\n",
        "        similarities = cosine_similarity(doc_embedding, sentence_embeddings)\n",
        "        top_indices = similarities.argsort()[0][-max_length:]\n",
        "\n",
        "        # 선택된 문장을 요약으로 반환\n",
        "        summary = [sentences[i] for i in top_indices]\n",
        "        return ' '.join(summary)\n",
        "\n",
        "    # 기사 요약\n",
        "    summary = summarize_text(content, max_length=3)\n",
        "    print(\"Summary:\", summary)\n",
        "\n",
        "    # 요약 내용을 로그로 출력하여 확인\n",
        "    print(\"요약된 내용:\", summary)\n",
        "\n",
        "    # 카카오 API를 사용하여 요약 내용 전송\n",
        "    def send_kakao_message(access_token, text):\n",
        "        url = 'https://kapi.kakao.com/v2/api/talk/memo/default/send'\n",
        "        headers = {\n",
        "            'Authorization': f'Bearer {access_token}'\n",
        "        }\n",
        "        data = {\n",
        "            'template_object': json.dumps({\n",
        "                'object_type': 'text',\n",
        "                'text': text,\n",
        "                'link': {\n",
        "                    'web_url': 'https://developers.kakao.com',\n",
        "                    'mobile_web_url': 'https://developers.kakao.com'\n",
        "                }\n",
        "            })\n",
        "        }\n",
        "\n",
        "        # 전송할 내용을 로그로 출력하여 확인\n",
        "        print(\"전송할 내용:\", text)\n",
        "\n",
        "        response = requests.post(url, headers=headers, data=data)\n",
        "        if response.status_code == 200:\n",
        "            print(\"Message sent successfully\")\n",
        "        else:\n",
        "            print(f\"Failed to send message: {response.json()}\")\n",
        "\n",
        "    # 발급받은 액세스 토큰 사용\n",
        "    access_token = '발급받은 액세스 토큰 입력'\n",
        "    send_kakao_message(access_token, summary)  # 요약된 내용을 전송합니다.\n",
        "else:\n",
        "    print(\"Failed to retrieve the webpage\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PfpgCIeuRgql",
        "outputId": "65c63103-54c1-45ed-f033-b4fa16b77972"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "뉴스 url을 입력해주세요: https://n.news.naver.com/article/005/0001705522?cds=news_media_pc&type=editn\n",
            "Summary: 의·정 갈등이 여전하고 의사를 향한 비난 여론이 잠잠해지지 않자 의대 교수들이 그동안 챙기지 않았던 그들의 권리를 찾겠다고 주장하고 나선 것으로 풀이된다.한편 대한의사협회(의협)를 필두로 한 의료계는 무기한 휴진 방침을 철회하지 않고 있다 이 소송에서 법원은 ‘의대 교수는 사립학교법상 대학 교원으로 병원 근로자로서 지위는 인정되지 않는다’며 수당을 지급할 의무가 없다고 판결했다 김 회장은 이날 한 의료 전문지와 인터뷰에서 ‘의대 교수는 근로자가 아니다’라고 판단한 사법부 판결을 언급하며 “의대 교수들은 근로 계약서도 쓰지 않은 상태로 병원에서 일하고 있다\n",
            "요약된 내용: 의·정 갈등이 여전하고 의사를 향한 비난 여론이 잠잠해지지 않자 의대 교수들이 그동안 챙기지 않았던 그들의 권리를 찾겠다고 주장하고 나선 것으로 풀이된다.한편 대한의사협회(의협)를 필두로 한 의료계는 무기한 휴진 방침을 철회하지 않고 있다 이 소송에서 법원은 ‘의대 교수는 사립학교법상 대학 교원으로 병원 근로자로서 지위는 인정되지 않는다’며 수당을 지급할 의무가 없다고 판결했다 김 회장은 이날 한 의료 전문지와 인터뷰에서 ‘의대 교수는 근로자가 아니다’라고 판단한 사법부 판결을 언급하며 “의대 교수들은 근로 계약서도 쓰지 않은 상태로 병원에서 일하고 있다\n",
            "전송할 내용: 의·정 갈등이 여전하고 의사를 향한 비난 여론이 잠잠해지지 않자 의대 교수들이 그동안 챙기지 않았던 그들의 권리를 찾겠다고 주장하고 나선 것으로 풀이된다.한편 대한의사협회(의협)를 필두로 한 의료계는 무기한 휴진 방침을 철회하지 않고 있다 이 소송에서 법원은 ‘의대 교수는 사립학교법상 대학 교원으로 병원 근로자로서 지위는 인정되지 않는다’며 수당을 지급할 의무가 없다고 판결했다 김 회장은 이날 한 의료 전문지와 인터뷰에서 ‘의대 교수는 근로자가 아니다’라고 판단한 사법부 판결을 언급하며 “의대 교수들은 근로 계약서도 쓰지 않은 상태로 병원에서 일하고 있다\n",
            "Message sent successfully\n"
          ]
        }
      ]
    }
  ]
}